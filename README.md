# TaskPilotAI - Phase 1

**The Evolution of Todo: In-Memory Python Console App**

Hackathon II Phase 1 (Due: Dec 7, 2025) - 100 Points

A spec-driven, test-first command-line todo application built using Claude Code and Spec-Kit Plus.

---

## âœ¨ Features

Phase 1 implements 5 basic level features:

1. **Add Task** â€“ Create new todo items with title and optional description
2. **Delete Task** â€“ Remove tasks from your list
3. **Update Task** â€“ Modify task title or description
4. **View Task List** â€“ Display tasks in table or JSON format with filtering
5. **Mark as Complete** â€“ Toggle task completion status (pending â†” completed)

---

## ğŸš€ Quick Start

### âš¡ Ultra Quick Start (30 seconds)

**Launch the interactive UI immediately:**

```bash
cd /home/bilal/TaskPilotAI
uv run python -m src.tui
```

**Menu appears with options 1-9. Try these:**
- Press `1` â†’ Add a task
- Press `2` â†’ View all tasks in table
- Press `7` â†’ Mark a task complete
- Press `0` â†’ Exit

Done! ğŸ‰

---

### Prerequisites

- **Python**: 3.13 or higher
- **UV**: Package manager for Python

### Installation

```bash
# Clone the repository
git clone https://github.com/92Bilal26/TaskPilotAI.git
cd TaskPilotAI

# Install dependencies using UV
uv sync --all-extras
```

---

### ğŸ® Two Ways to Use

#### Option 1: Interactive UI (Recommended)

**Beautiful menu-driven interface with tables, formatting, and statistics:**

```bash
uv run python -m src.tui
```

**Menu Options:**
```
1ï¸âƒ£  Add New Task           â†’ Create new task with title & description
2ï¸âƒ£  View All Tasks         â†’ Display all tasks in beautiful table format
3ï¸âƒ£  View All Tasks (JSON)  â†’ Display tasks in JSON format
4ï¸âƒ£  View Pending Tasks     â†’ Show only incomplete tasks
5ï¸âƒ£  View Completed Tasks   â†’ Show only completed tasks
6ï¸âƒ£  Update Task           â†’ Modify task title or description
7ï¸âƒ£  Mark Task Complete    â†’ Toggle task completion status
8ï¸âƒ£  Delete Task           â†’ Remove task from list
9ï¸âƒ£  View Statistics       â†’ See progress and task statistics
0ï¸âƒ£  Exit                  â†’ Close application
```

**Example Walkthrough:**
1. Press `1` â†’ Enter title "Buy groceries" â†’ Enter description "Milk, eggs, bread" â†’ âœ… Task created
2. Press `2` â†’ See beautiful table with all tasks
3. Press `7` â†’ Enter ID `1` â†’ Task marked complete âœ…
4. Press `9` â†’ See statistics showing 1/1 tasks completed

#### Option 2: Command Line (For Automation/Scripts)

```bash
# Add a task
uv run python src/main.py add --title "Buy groceries" --description "Milk, eggs, bread"

# List all tasks
uv run python src/main.py list

# List pending tasks only
uv run python src/main.py list --status pending

# List tasks as JSON
uv run python src/main.py list --json

# Update a task
uv run python src/main.py update --id 1 --title "Buy groceries and fruits"

# Mark task as complete
uv run python src/main.py complete --id 1

# Delete a task
uv run python src/main.py delete --id 1
```

---

### ğŸ“š Comprehensive Guides

This project includes detailed guides for all aspects:

| Guide | Purpose | Best For |
|-------|---------|----------|
| **QUICK_START.md** | 30-second setup + 2-minute demo | Getting started quickly |
| **TUI_GUIDE.md** | Complete interactive menu guide | Understanding all UI features |
| **TESTING_GUIDE.md** | Testing instructions + 10 scenarios | Verifying everything works |
| **CLAUDE.md** | Development methodology & architecture | Understanding the codebase |
| **/specs/** | Detailed feature specifications | Deep technical understanding |

---

## ğŸ—ï¸ Project Structure

```
TaskPilotAI/
â”œâ”€â”€ specs/                              # Specifications (Spec-Kit Plus)
â”‚   â”œâ”€â”€ overview.md                     # Project overview
â”‚   â”œâ”€â”€ data-models.md                  # Data model definitions
â”‚   â””â”€â”€ features/                       # Feature specifications
â”‚       â”œâ”€â”€ 01-add-task.md
â”‚       â”œâ”€â”€ 02-delete-task.md
â”‚       â”œâ”€â”€ 03-update-task.md
â”‚       â”œâ”€â”€ 04-view-tasks.md
â”‚       â””â”€â”€ 05-mark-complete.md
â”‚
â”œâ”€â”€ src/                                # Source code
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â”œâ”€â”€ main.py                         # CLI entry point
â”‚   â”œâ”€â”€ models.py                       # Task data model
â”‚   â”œâ”€â”€ storage.py                      # In-memory storage manager
â”‚   â””â”€â”€ commands.py                     # Command handlers
â”‚
â”œâ”€â”€ tests/                              # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                     # Pytest fixtures
â”‚   â”œâ”€â”€ test_add_task.py                # Add task tests
â”‚   â”œâ”€â”€ test_delete_task.py             # Delete task tests
â”‚   â”œâ”€â”€ test_update_task.py             # Update task tests
â”‚   â”œâ”€â”€ test_view_tasks.py              # View tasks tests
â”‚   â””â”€â”€ test_mark_complete.py           # Mark complete tests
â”‚
â”œâ”€â”€ .specify/                           # Spec-Kit Plus config
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ constitution.md             # Project constitution
â”‚   â”œâ”€â”€ scripts/bash/                   # Helper scripts
â”‚   â””â”€â”€ templates/                      # Spec templates
â”‚
â”œâ”€â”€ .claude/commands/                   # Claude Code commands
â”œâ”€â”€ history/prompts/                    # Prompt History Records
â”œâ”€â”€ pyproject.toml                      # Project configuration (UV)
â”œâ”€â”€ pytest.ini                          # Pytest configuration
â”œâ”€â”€ CLAUDE.md                           # Claude Code guidelines
â”œâ”€â”€ README.md                           # This file
â””â”€â”€ .gitignore                          # Git ignore rules
```

---

## ğŸ§ª Testing

### Run All Tests

```bash
# Run all tests with verbose output
pytest -v

# Run tests with coverage report
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_add_task.py -v

# Run tests matching a pattern
pytest -k "test_add" -v
```

### Test Coverage

Phase 1 aims for **â‰¥95% code coverage**. After running tests with coverage:

```bash
# View coverage report in terminal
pytest --cov=src --cov-report=term-missing

# Generate HTML coverage report
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

---

## ğŸ” Code Quality

### Type Checking

```bash
# Run mypy for type checking
mypy src/

# Check with strict mode
mypy --strict src/
```

### Linting

```bash
# Run flake8 for style checking
flake8 src/ tests/

# Check with specific rules
flake8 src/ --show-source --statistics
```

### Format Code (Optional)

```bash
# Format code with black
black src/ tests/

# Check formatting without changes
black --check src/ tests/
```

### Quality Gates (All Required)

```bash
# Run all quality checks
pytest -v --cov=src
mypy src/
flake8 src/ tests/
```

All quality gates must pass before submission.

---

## ğŸ“ Development Workflow

This project follows **Spec-Driven Development** with strict **Test-First (TDD)** methodology:

### 1. Specification Phase
- Read feature specification in `/specs/features/`
- Understand requirements, acceptance criteria, and data model
- Clarify any ambiguities

### 2. Test Phase (Red)
- Write failing tests based on specification
- Tests define expected behavior
- Run `pytest` â†’ all tests fail initially

### 3. Implementation Phase (Green)
- Write minimum code to pass all tests
- Follow Python best practices (PEP 8, type hints, docstrings)
- Run `pytest` â†’ all tests pass

### 4. Refactor Phase
- Clean up code for readability and maintainability
- Ensure all tests still pass
- No behavioral changes

### 5. Quality Verification
```bash
pytest -v --cov=src      # Tests & coverage
mypy src/                # Type checking
flake8 src/              # Code style
```

### 6. Document
- Update docstrings and comments
- Create Prompt History Record (PHR)
- Update README if user-facing behavior changed

---

## ğŸ“Š Data Model

### Task Object

```python
{
  "id": int,                    # Auto-incremented, unique
  "title": str,                 # Required, 1-200 characters
  "description": str,           # Optional, max 1000 characters
  "completed": bool,            # False (pending) or True (completed)
  "created_at": str,            # ISO 8601 datetime
  "updated_at": str             # ISO 8601 datetime
}
```

### Example Task

```json
{
  "id": 1,
  "title": "Buy groceries",
  "description": "Milk, eggs, bread",
  "completed": false,
  "created_at": "2025-12-07T10:30:00",
  "updated_at": "2025-12-07T10:30:00"
}
```

---

## âš ï¸ Error Handling

The application provides clear, actionable error messages:

| Error | Message | Exit Code |
|---|---|---|
| Task not found | `Error: Task ID X not found` | 1 |
| Invalid title | `Error: Title required (1-200 characters)` | 1 |
| Invalid description | `Error: Description max 1000 characters` | 1 |
| Missing argument | `Error: --id is required` | 1 |
| System error | `Error: Unexpected error occurred` | 2 |

---

## ğŸ“– CLI Commands Reference

### Add Task
```bash
python src/main.py add --title "Task title" [--description "Optional description"]

# Examples
python src/main.py add --title "Buy groceries"
python src/main.py add --title "Buy groceries" --description "Milk, eggs, bread"
```

### Delete Task
```bash
python src/main.py delete --id <task_id>

# Example
python src/main.py delete --id 1
```

### Update Task
```bash
python src/main.py update --id <task_id> [--title "New title"] [--description "New description"]

# Examples
python src/main.py update --id 1 --title "New title"
python src/main.py update --id 1 --description "New description"
python src/main.py update --id 1 --title "New" --description "New desc"
```

### List Tasks
```bash
python src/main.py list [--status <status>] [--json]

# Examples
python src/main.py list                          # Show all tasks
python src/main.py list --status pending        # Show pending only
python src/main.py list --status completed      # Show completed only
python src/main.py list --json                  # JSON output
```

### Mark Task as Complete
```bash
python src/main.py complete --id <task_id>

# Example
python src/main.py complete --id 1
```

---

## ğŸ”§ Technology Stack

| Component | Technology | Purpose |
|---|---|---|
| **Language** | Python 3.13+ | Implementation |
| **Package Manager** | UV | Dependency management |
| **Testing** | pytest | Test framework |
| **Type Checking** | mypy | Static type verification |
| **Linting** | flake8 | Code style enforcement |
| **Coverage** | pytest-cov | Coverage measurement |

### Runtime Dependencies
âœ… **Zero external dependencies** â€“ Only Python standard library

### Development Dependencies
- pytest
- pytest-cov
- mypy
- flake8

---

## ğŸ¯ Quality Standards

### Code Quality
- **Style**: PEP 8 compliant (enforced by flake8)
- **Type Hints**: 100% type hints on all functions
- **Documentation**: Docstrings for all classes and public methods
- **Coverage**: â‰¥95% code coverage (enforced by pytest-cov)
- **Type Safety**: 100% mypy compliance (strict mode)

### Testing
- **Unit Tests**: Each function has â‰¥1 test
- **Integration Tests**: Full CLI workflows tested
- **Edge Cases**: Boundary conditions and error cases tested
- **Data Integrity**: ID sequences, state transitions verified

### Documentation
- **README.md**: Setup and usage instructions
- **CLAUDE.md**: Claude Code development guidelines
- **Specs**: Detailed feature specifications in `/specs/`
- **Code Comments**: Self-documenting code, minimal comments

---

## ğŸ“š Phase 1 Constitution

This project follows a strict **Constitution** defined in `.specify/memory/constitution.md`. The constitution establishes:

- **Core Principles**: Spec-driven development, test-first TDD, in-memory storage
- **Quality Gates**: All 8 gates must pass before submission
- **Error Standards**: Consistent error messages and exit codes
- **Non-Negotiable Rules**: Cannot skip specs, cannot code without tests, zero external dependencies

**Key Constraint**: Cannot write code manually. Specs must be refined until Claude Code generates correct output.

---

## ğŸš€ Next Steps (Phase 2+)

Phase 1 focuses on core logic. Future phases will add:

- **Phase 2**: Full-stack web application (Next.js + FastAPI + PostgreSQL)
- **Phase 3**: AI chatbot with natural language interface
- **Phase 4**: Kubernetes deployment (Minikube)
- **Phase 5**: Cloud deployment (DigitalOcean DOKS) + Kafka + Dapr

---

## ğŸ“ Contributing

This is a hackathon project following strict spec-driven development. All contributions must:

1. Start with a specification in `/specs/`
2. Include comprehensive tests (TDD)
3. Pass all quality gates (pytest, mypy, flake8)
4. Follow the constitution principles

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ‘¤ Author

**92Bilal26** (Bilal Ahmed)
- Email: talibebaqi@gmail.com
- GitHub: https://github.com/92Bilal26

---

## ğŸ”— Resources

- **Project Repository**: https://github.com/92Bilal26/TaskPilotAI
- **Phase 1 Branch**: https://github.com/92Bilal26/TaskPilotAI/tree/phase-1
- **Hackathon Info**: Evolution of Todo - Hackathon II
- **Constitution**: `.specify/memory/constitution.md`
- **Specifications**: `/specs/` directory

---

## ğŸ“ Support

For questions or issues:

1. Check the specification files in `/specs/`
2. Review the constitution in `.specify/memory/constitution.md`
3. Check existing tests in `/tests/` for examples
4. Open an issue on GitHub

---

**Last Updated**: 2025-12-07
**Status**: Phase 1 Implementation
**Next Milestone**: Dec 7, 2025 (Phase 1 Deadline)
